import dlt
from pyspark.sql.functions import *

@dlt.table(
    name="bronze_vin_data",
    comment="Bronze streaming table for VIN data",
    table_properties={"quality": "bronze"}
)
def bronze_vin_data():
    return (
        spark.readStream  # Use readStream for continuous ingestion
        .table("editorial.vin_data")  # Read from the existing table
        .withColumnRenamed("vin", "vin8")  # Rename VIN column
    )
